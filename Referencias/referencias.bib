
@mastersthesis{costa_otimizacao_2023,
	address = {São José dos Campos},
	type = {Mestrado},
	title = {Otimização de {Trajetória} de {Subida} de {eVTOL} utilizando o {Método} de {Colocação} {Direta}},
	language = {pt},
	school = {Instituto Tecnológico de Aeronáutica},
	author = {Costa, Andrei Luswarghi Souza},
	year = {2023},
	file = {OTIMIZAÇÃO DE TRAJETÓRIA DE SUBIDA DE EVTOL UTILIZANDO O MÉTODO DE COLOCAÇÃO DIRETA:C\:\\Users\\henri\\Zotero\\storage\\6IVZGHLL\\OTIMIZAÇÃO DE TRAJETÓRIA DE SUBIDA DE EVTOL UTILIZANDO O MÉTODO DE COLOCAÇÃO DIRETA.pdf:application/pdf},
}

@article{kelly_introduction_2017,
	title = {An {Introduction} to {Trajectory} {Optimization}:  {How} to {Do} {Your} {Own} {Direct} {Collocation}},
	volume = {59},
	issn = {0036-1445},
	shorttitle = {An {Introduction} to {Trajectory} {Optimization}},
	url = {https://epubs.siam.org/doi/10.1137/16M1062569},
	doi = {10.1137/16M1062569},
	abstract = {In this paper, we consider a discontinuous Galerkin finite element method for first order initial-final value problems arising from optimal control of launch vehicles. In particular, we derive an a posteriori error estimate for this method that is subsequently implemented to provide a computational error estimate used for adaptive error control. We discuss several practical issues in the implementation of the computational error estimate as well. We test the theory on a real-life trajectory problem and find that the estimates are reliable and accurate while the adaptive error control leads to a significant gain in efficiency.},
	number = {4},
	urldate = {2024-06-11},
	journal = {SIAM Review},
	author = {Kelly, Matthew},
	month = jan,
	year = {2017},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	pages = {849--904},
	file = {Full Text PDF:C\:\\Users\\henri\\Zotero\\storage\\DEK3YXSB\\Kelly - 2017 - An Introduction to Trajectory Optimization  How t.pdf:application/pdf},
}

@misc{becerra_psopt_2022,
	title = {{PSOPT} {Optimal} {Control} {Solver}: {User} {Manual}},
	url = {https://github.com/PSOPT/psopt/releases/tag/5.02},
	urldate = {2024-06-12},
	author = {Becerra, Victor},
	month = mar,
	year = {2022},
	file = {Becerra - 2022 - PSOPT Optimal Control Solver User Manual.pdf:C\:\\Users\\henri\\Zotero\\storage\\QLR6D6H8\\Becerra - 2022 - PSOPT Optimal Control Solver User Manual.pdf:application/pdf},
}

@book{lewis_optimal_2012,
	title = {Optimal {Control}},
	isbn = {978-1-118-12272-3},
	abstract = {A NEW EDITION OF THE CLASSIC TEXT ON OPTIMAL CONTROL THEORY As a superb introductory text and an indispensable reference, this new edition of Optimal Control will serve the needs of both the professional engineer and the advanced student in mechanical, electrical, and aerospace engineering. Its coverage encompasses all the fundamental topics as well as the major changes that have occurred in recent years. An abundance of computer simulations using MATLAB and relevant Toolboxes is included to give the reader the actual experience of applying the theory to real-world situations. Major topics covered include:  Static Optimization Optimal Control of Discrete-Time Systems Optimal Control of Continuous-Time Systems The Tracking Problem and Other LQR Extensions Final-Time-Free and Constrained Input Control Dynamic Programming Optimal Control for Polynomial Systems Output Feedback and Structured Control Robustness and Multivariable Frequency-Domain Techniques Differential Games Reinforcement Learning and Optimal Adaptive Control},
	language = {en},
	publisher = {John Wiley \& Sons},
	author = {Lewis, Frank L. and Vrabie, Draguna and Syrmos, Vassilis L.},
	month = mar,
	year = {2012},
	note = {Google-Books-ID: U3Gtlot\_hYEC},
	keywords = {Technology \& Engineering / Manufacturing, Technology \& Engineering / Mechanical, Technology \& Engineering / Robotics},
	file = {Lewis et al. - 2012 - Optimal Control.pdf:C\:\\Users\\henri\\Zotero\\storage\\XURSJZMD\\Lewis et al. - 2012 - Optimal Control.pdf:application/pdf},
}

@inproceedings{kek_nonlinear_2013,
	title = {Nonlinear programming approach for optimal control problems},
	url = {https://www.researchgate.net/profile/Mohamed-Mourad-Lafifi/post/How_to_formulate_the_nonlinear_optimal_control_problem_to_nonlinear_programming/attachment/609918213164270001d9cc78/AS%3A1021873345265666%401620644999740/download/Nonlinear+Programming+Approach+For+Optimal+Control+Problems.pdf},
	urldate = {2024-06-12},
	booktitle = {Proceeding of the 2nd {International} {Conference} on {Global} {Optimization} and {Its} {Applications}},
	author = {Kek, Sie-Long},
	year = {2013},
	pages = {20--25},
	file = {Available Version (via Google Scholar):C\:\\Users\\henri\\Zotero\\storage\\FEDWZ3JX\\Kek - 2013 - Nonlinear programming approach for optimal control.pdf:application/pdf},
}

@book{betts_practical_2010,
	title = {Practical {Methods} for {Optimal} {Control} and {Estimation} {Using} {Nonlinear} {Programming}: {Second} {Edition}},
	isbn = {978-0-89871-857-7},
	shorttitle = {Practical {Methods} for {Optimal} {Control} and {Estimation} {Using} {Nonlinear} {Programming}},
	abstract = {The book describes how sparse optimization methods can be combined with discretization techniques for differential-algebraic equations and used to solve optimal control and estimation problems. The interaction between optimization and integration is emphasized throughout the book.},
	language = {en},
	publisher = {SIAM},
	author = {Betts, John T.},
	month = jan,
	year = {2010},
	note = {Google-Books-ID: n9hLriD8Lb8C},
	keywords = {Technology \& Engineering / Robotics, Mathematics / Applied, Mathematics / Discrete Mathematics, Mathematics / General, Mathematics / Optimization},
}

@article{betts_survey_1998,
	title = {Survey of {Numerical} {Methods} for {Trajectory} {Optimization}},
	volume = {21},
	issn = {0731-5090},
	url = {https://arc.aiaa.org/doi/10.2514/2.4231},
	doi = {10.2514/2.4231},
	number = {2},
	urldate = {2024-06-12},
	journal = {Journal of Guidance, Control, and Dynamics},
	author = {Betts, John T.},
	month = mar,
	year = {1998},
	note = {Publisher: American Institute of Aeronautics and Astronautics},
	keywords = {Applied Mathematics, Astronautics, Boeing, Boundary Value Problems, Computing, Direct Multiple Shooting Method, Expendable Launch Vehicle, Hamilton Jacobi Bellman Equation, Nonlinear Programming, Sequential Quadratic Programming},
	pages = {193--207},
	file = {Betts - A Survey of Numerical Methods for Trajectory Optim.pdf:C\:\\Users\\henri\\Zotero\\storage\\HV966MAD\\Betts - A Survey of Numerical Methods for Trajectory Optim.pdf:application/pdf},
}

@misc{kelly_optimtraj_2022,
	title = {{OptimTraj}: {Trajectory} {Optimization} for {Matlab}},
	url = {https://github.com/MatthewPeterKelly/OptimTraj},
	author = {Kelly, Matthew Peter},
	month = dec,
	year = {2022},
	doi = {10.5281/zenodo.7430524},
}

@article{resende_solving_2019,
	title = {Solving {Optimal} {Control} {Problems} by {Numerical} {Simulations}: {A} {Literature} {Review}},
	volume = {1},
	copyright = {Copyright (c) 2020 Revista Integra??o Engenharia},
	issn = {2596-0865},
	shorttitle = {Solving {Optimal} {Control} {Problems} by {Numerical} {Simulations}},
	url = {https://integracao.feb.unesp.br/index.php/RIE/article/view/11},
	language = {pt},
	urldate = {2024-06-12},
	author = {Resende, Ranulfo Acir de Oliveira},
	year = {2019},
	file = {Full Text PDF:C\:\\Users\\henri\\Zotero\\storage\\A6KUYULQ\\Resende - 2019 - Solving Optimal Control Problems by Numerical Simu.pdf:application/pdf},
}

@article{diveev_solution_2021,
	series = {14th {International} {Symposium} "{Intelligent} {Systems}},
	title = {Solution of the optimal control problem by symbolic regression method},
	volume = {186},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050921010590},
	doi = {10.1016/j.procs.2021.04.212},
	abstract = {The paper introduces an approach to solve the optimal control problem applying symbolic regression methods. All known approaches to solve the optimal control problem are based on direct or indirect methods. Indirect methods may provide analytical solution but impose restrictions on the form and dimension of control object. In direct ones the optimal control problem is reduced to the nonlinear programming problem which provides general numerical solution. Also direct methods impose no restrictions on control object and have a wide range of application to complex applied problems. The approach proposed combines the advantages of both direct and indirect methods not involving the disadvantages mentioned previously. The suggested approach provides solution to the optimal control problem as a control function of time in explicit form. This approach benefits in case of applied optimal control problem requiring a solution in explicit form while indirect methods are inapplicable due to the restrictions imposed on the control system. The computational experiment of solving the optimal control problem for a mobile robot with phase constraints is presented. The results illustrate that the proposed approach finds an optimal control as a function of time which provides a mobile robot’s motion along the optimal trajectory avoiding phase constraints.},
	urldate = {2024-06-13},
	journal = {Procedia Computer Science},
	author = {Diveev, A. I. and Konstantinov, S. V. and Danilova, A. M.},
	month = jan,
	year = {2021},
	keywords = {evolutionary algorithms, optimal control problem, symbolic regression methods},
	pages = {646--653},
	file = {ScienceDirect Snapshot:C\:\\Users\\henri\\Zotero\\storage\\87MYETXF\\S1877050921010590.html:text/html},
}

@book{athans_optimal_2007,
	title = {Optimal {Control}: {An} {Introduction} to the {Theory} and {Its} {Applications}},
	isbn = {978-0-486-45328-6},
	shorttitle = {Optimal {Control}},
	abstract = {Geared toward advanced undergraduate and graduate engineering students, this text introduces the theory and applications of optimal control. It serves as a bridge to the technical literature, enabling students to evaluate the implications of theoretical control work, and to judge the merits of papers on the subject. Rather than presenting an exhaustive treatise, Optimal Control offers a detailed introduction that fosters careful thinking and disciplined intuition. It develops the basic mathematical background, with a coherent formulation of the control problem and discussions of the necessary conditions for optimality based on the maximum principle of Pontryagin. In-depth examinations cover applications of the theory to minimum time, minimum fuel, and to quadratic criteria problems. The structure, properties, and engineering realizations of several optimal feedback control systems also receive attention. Special features include numerous specific problems, carried through to engineering realization in block diagram form. The text treats almost all current examples of control problems that permit analytic solutions, and its unified approach makes frequent use of geometric ideas to encourage students\&\#39; intuition.},
	language = {en},
	publisher = {Courier Corporation},
	author = {Athans, Michael and Falb, Peter L.},
	month = jan,
	year = {2007},
	note = {Google-Books-ID: XJJDTSZ2HEEC},
	keywords = {Technology \& Engineering / Robotics, Technology \& Engineering / Automation, Technology \& Engineering / Engineering (General)},
}

@book{kirk_optimal_2004,
	title = {Optimal {Control} {Theory}: {An} {Introduction}},
	isbn = {978-0-486-43484-1},
	shorttitle = {Optimal {Control} {Theory}},
	abstract = {Optimal control theory is the science of maximizing the returns from and minimizing the costs of the operation of physical, social, and economic processes. Geared toward upper-level undergraduates, this text introduces three aspects of optimal control theory: dynamic programming, Pontryagin\&\#39;s minimum principle, and numerical techniques for trajectory optimization. Chapters 1 and 2 focus on describing systems and evaluating their performances. Chapter 3 deals with dynamic programming. The calculus of variations and Pontryagin\&\#39;s minimum principle are the subjects of chapters 4 and 5, and chapter 6 examines iterative numerical techniques for finding optimal controls and trajectories. Numerous problems, intended to introduce additional topics as well as to illustrate basic concepts, appear throughout the text.},
	language = {en},
	publisher = {Courier Corporation},
	author = {Kirk, Donald E.},
	month = jan,
	year = {2004},
	note = {Google-Books-ID: fCh2SAtWIdwC},
	keywords = {Computers / Cybernetics, Technology \& Engineering / Electronics / General},
}

@book{bryson_applied_2018,
	title = {Applied {Optimal} {Control}: {Optimization}, {Estimation} and {Control}},
	isbn = {978-1-351-46592-2},
	shorttitle = {Applied {Optimal} {Control}},
	abstract = {This best-selling text focuses on the analysis and design of complicated dynamics systems. CHOICE called it ""a high-level, concise book that could well be used as a reference by engineers, applied mathematicians, and undergraduates. The format is good, the presentation clear, the diagrams instructive, the examples and problems helpful...References and a multiple-choice examination are included.},
	language = {en},
	publisher = {Routledge},
	author = {Bryson, A. E.},
	month = may,
	year = {2018},
	note = {Google-Books-ID: LFUPEAAAQBAJ},
	keywords = {Technology \& Engineering / Electrical, Technology \& Engineering / Environmental / General, Technology \& Engineering / Power Resources / General},
}

@article{becerra_optimal_2008,
	title = {Optimal control},
	volume = {3},
	issn = {1941-6016},
	url = {http://www.scholarpedia.org/article/Optimal_control},
	doi = {10.4249/scholarpedia.5354},
	language = {en},
	number = {1},
	urldate = {2024-06-14},
	journal = {Scholarpedia},
	author = {Becerra, Victor M.},
	month = jan,
	year = {2008},
	pages = {5354},
}

@book{pontryagin_mathematical_1987,
	title = {Mathematical {Theory} of {Optimal} {Processes}},
	isbn = {978-2-88124-077-5},
	abstract = {The fourth and final volume in this comprehensive set presents the maximum principle as a wide ranging solution to nonclassical, variational problems. This one mathematical method can be applied in a variety of situations, including linear equations with variable coefficients, optimal processes with delay, and the jump condition. As with the three preceding volumes, all the material contained with the 42 sections of this volume is made easily accessible by way of numerous examples, both concrete and abstract in nature.},
	language = {en},
	publisher = {CRC Press},
	author = {Pontryagin, L. S.},
	month = mar,
	year = {1987},
	note = {Google-Books-ID: kwzq0F4cBVAC},
	keywords = {Mathematics / Applied, Mathematics / General},
}

@article{kalman_new_1960,
	title = {A {New} {Approach} to {Linear} {Filtering} and {Prediction} {Problems}},
	volume = {82},
	issn = {0021-9223},
	url = {https://doi.org/10.1115/1.3662552},
	doi = {10.1115/1.3662552},
	abstract = {The classical filtering and prediction problem is re-examined using the Bode-Shannon representation of random processes and the “state-transition” method of analysis of dynamic systems. New results are: (1) The formulation and methods of solution of the problem apply without modification to stationary and nonstationary statistics and to growing-memory and infinite-memory filters. (2) A nonlinear difference (or differential) equation is derived for the covariance matrix of the optimal estimation error. From the solution of this equation the co-efficients of the difference (or differential) equation of the optimal linear filter are obtained without further calculations. (3) The filtering problem is shown to be the dual of the noise-free regulator problem. The new method developed here is applied to two well-known problems, confirming and extending earlier results. The discussion is largely self-contained and proceeds from first principles; basic concepts of the theory of random processes are reviewed in the Appendix.},
	number = {1},
	urldate = {2024-06-17},
	journal = {Journal of Basic Engineering},
	author = {Kálmán, Rudolf Emil},
	month = mar,
	year = {1960},
	pages = {35--45},
}

@inproceedings{kalman_contributions_1960,
	title = {Contributions to the {Theory} of {Optimal} {Control}},
	url = {https://www.semanticscholar.org/paper/Contributions-to-the-Theory-of-Optimal-Control-K%C3%A1lm%C3%A1n/4602a97c4965a9f6c41c9a7eeaef5be8333dbaef},
	abstract = {THIS is one of the two ground-breaking papers by Kalman that appeared in 1960—with the other one (discussed next) being the filtering and prediction paper. This first paper, which deals with linear-quadratic feedback control, set the stage for what came to be known as LQR (Linear-Quadratic-Regulator) control, while the combination of the two papers formed the basis for LQG (Linear-Quadratic-Gaussian) control. Both LQR and LQG control had major influence on researchers, teachers, and practitioners of control in the decades that followed. The idea of designing a feedback controller such that the integral of the square of tracking error is minimized was first proposed by Wiener [17] and Hall [8], and further developed in the influential book by Newton, Gould and Kaiser [12]. However, the problem formulation in this book remained unsatisfactory from a mathematical point of view, but, more importantly, the algorithms obtained allowed application only to rather low order systems and were thus of limited value. This is not surprising since it basically took until theH2-interpretation in the 1980s of LQG control before a satisfactory formulation of least squares feedback control design was obtained. Kalman’s formulation in terms of finding the least squares control that evolves from an arbitrary initial state is a precise formulation of the optimal least squares transient control problem. The paper introduced the very important notion of c ntrollability, as the possibility of transfering any initial state to zero by a suitable control action. It includes the necessary and sufficient condition for controllability in terms of the positive definiteness of the Controllability Grammian, and the fact that the linear time-invariant system withn states,},
	urldate = {2024-06-17},
	author = {Kálmán, Rudolf Emil},
	year = {1960},
	file = {Full Text PDF:C\:\\Users\\henri\\Zotero\\storage\\VIPXGZYD\\Kálmán - 1960 - Contributions to the Theory of Optimal Control.pdf:application/pdf},
}

@book{bellman_dynamic_2010,
	title = {Dynamic {Programming}},
	isbn = {978-0-691-14668-3},
	abstract = {This classic book is an introduction to dynamic programming, presented by the scientist who coined the term and developed the theory in its early stages. In Dynamic Programming, Richard E. Bellman introduces his groundbreaking theory and furnishes a new and versatile mathematical tool for the treatment of many complex problems, both within and outside of the discipline. The book is written at a moderate mathematical level, requiring only a basic foundation in mathematics, including calculus. The applications formulated and analyzed in such diverse fields as mathematical economics, logistics, scheduling theory, communication theory, and control processes are as relevant today as they were when Bellman first presented them. A new introduction by Stuart Dreyfus reviews Bellman's later work on dynamic programming and identifies important research areas that have profited from the application of Bellman's theory.},
	language = {en},
	publisher = {Princeton University Press},
	author = {Bellman, Richard},
	month = jul,
	year = {2010},
	note = {Google-Books-ID: 92aYDwAAQBAJ},
	keywords = {Computers / Computer Science, Computers / Software Development \& Engineering / Systems Analysis \& Design, Mathematics / Applied, Mathematics / Discrete Mathematics, Mathematics / Linear \& Nonlinear Programming, Mathematics / Optimization},
}

@article{sussmann_300_1997,
	title = {300 years of optimal control: from the brachystochrone to the maximum principle},
	volume = {17},
	issn = {1941-000X},
	shorttitle = {300 years of optimal control},
	url = {https://ieeexplore.ieee.org/document/588098},
	doi = {10.1109/37.588098},
	abstract = {An historical review of the development of optimal control from the publication of the brachystochrone problem by Johann Bernoulli in 1696. Ideas on curve minimization already known at the time are briefly outlined. The brachystochrone problem is stated and Bernoulli's solution is given. Bernoulli's personality and his family are discussed. The article then traces the development of the necessary conditions for a minimum, from the Euler-Lagrange equations to the work of Legendre and Weierstrass and, eventually, the maximum principle of optimal control theory.},
	number = {3},
	urldate = {2024-06-17},
	journal = {IEEE Control Systems Magazine},
	author = {Sussmann, H.J. and Willems, J.C.},
	month = jun,
	year = {1997},
	note = {Conference Name: IEEE Control Systems Magazine},
	keywords = {Centralized control, Cities and towns, Cost function, Equations, History, Mathematics, Optimal control, Reflection, Sufficient conditions},
	pages = {32--44},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\henri\\Zotero\\storage\\GV2IRZ6G\\Sussmann e Willems - 1997 - 300 years of optimal control from the brachystoch.pdf:application/pdf},
}

@techreport{paine_application_1967,
	type = {tech},
	title = {The application of the method of quasilinearization to the computation of optimal control},
	url = {https://ntrs.nasa.gov/api/citations/19680002402/downloads/19680002402.pdf},
	number = {NASA-CR-90749},
	urldate = {2024-06-17},
	author = {Paine, G.},
	month = aug,
	year = {1967},
	file = {19680002402.pdf:C\:\\Users\\henri\\Zotero\\storage\\HFAQIILT\\19680002402.pdf:application/pdf},
}
